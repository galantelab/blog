---
layout: post
title: "A navalha e o labirinto: neurodegeneração, simplificação e o lugar da Inteligência Artificial"
author: lfarina
categories: [ "Heterogeneidade", "Inteligência Artificial", "Neurodegeneração" ]
image: assets/images/16.jpg
---

Em neurodegeneração, o primeiro desafio não é a complexidade do cérebro 
— é fingir que ela não existe. As doenças neurodegenerativas não se 
comportam como um defeito único a corrigir – como muitas moléstias que 
afetam a saúde humana, povoando o imaginário das pessoas e de muitos 
profissionais –, mas como trajetórias que atravessam genética, 
epigenética, metabolismo e imunidade, sinapses e redes neurais, tudo isso 
evoluindo ao longo do tempo de vida de cada pessoa. A mesma etiqueta 
diagnóstica abrange subtipos com ritmos, sintomas e respostas distintas. 
Resultados que parecem inequívocos na média podem “inverter o sinal” 
quando analisamos por idade, sexo, comorbidades e/ou ambiente. Pequenas 
alterações moleculares se amplificam em circuitos; episódios discretos 
somam-se até ultrapassar limiares. Processos que, num momento, protegem, no 
seguinte, desorganizam. Começar por esse terreno concreto — multiescala, 
heterogêneo e dinâmico — é reconhecer que o custo de simplificar demais 
pode ser elevado. É reconhecer que há certa ordem no caos, mas que tal ordem 
precisa ser desvendada.

Diante desse labirinto, a ciência recorre a um princípio antigo e amplamente 
utilizado, tão utilizado que passou a fazer parte do nosso repertório 
intelectual: a Navalha de Ockham (para saber mais: 
<https://pt.wikipedia.org/wiki/Navalha_de_Ockham>). Se um fenômeno tem várias 
explicações, a mais simples e com menor número de premissas é a mais 
correta. Conhecido também como princípio da parcimônia. A parcimônia 
desincha hipóteses, melhora a testabilidade, organiza o debate e torna a 
comunicação científica mais clara e, no geral, mas simples de ser entendida. 
Sem ela, qualquer dado explicaria qualquer coisa. Mas a navalha é uma 
heurística, não uma lei da natureza. Em sistemas não lineares e contextuais, 
a busca por um único agente tende a apagar relações condicionais, efeitos de 
interação e relações temporais cruciais. Simplificar para agir é 
necessário; mutilar para caber é um erro. Em neurodegeneração, reduzir 
permite trabalhar, mas só reduzir não basta para acertar.

Três armadilhas ajudam a visualizar esse ponto. A primeira é a média que 
mente: padrões que surgem na população desaparecem — ou até se invertem 
— quando analisamos subgrupos, o velho lembrete do paradoxo de Simpson (para 
saber mais <https://pt.wikipedia.org/wiki/Paradoxo_de_Simpson>). A segunda é o 
indicador que vira fim: quando transformamos um biomarcador em meta, deixamos 
de medir o que importa, a conhecida lei de Goodhart 
(<https://pt.wikipedia.org/wiki/Lei_de_Goodhart>). Na clínica, a vitória em um 
indicador pode coexistir com fracasso em desfechos funcionais. Exemplo claro 
das terapias anti-amiloide na Doença de Alzheimer, com medicamentos altamente 
efetivos em diminuição de marcadores, porém com baixo impacto no que 
realmente importa – cognição e melhora da qualidade de vida. A terceira é 
a causalidade que evapora: correlações limpas em dados agregados se desfazem 
quando repomos a temporalidade e o mecanismo; o que hoje compensa, amanhã pode 
lesar. A boa parcimônia remove excesso de explicação sem cortar o fio causal 
nem a textura do contexto.

A descoberta dos elementos genéticos móveis exemplifica o caso. Por décadas, 
vastas regiões do DNA humano foram chamadas de “junk DNA”. Ali 
localizam-se os elementos genéticos móveis (também chamados de elementos 
transponíveis) — sequências capazes de copiar-se e inserir-se em novos 
locais do genoma. À primeira vista, tudo isso soa improvável: por que a 
natureza manteria tantos “passageiros” no nosso e no genomas de outras 
espécies? No entanto, a história recente virou a narrativa. O que parecia 
ruído revela-se fonte de material genético funcional: trechos que funcionam 
como promotores e enhancers, rotas de plasticidade que células e organismos 
cooptaram ao longo da evolução. Em certos contextos, porém, os mesmos 
elementos contribuem para a desorganização de um genoma ou estado celular. Em 
neurodegeneração, esse “não usual” importa — e muito.

Com o envelhecimento, a regulamentação epigenética desses elementos torna-se 
irregular entre diferentes tipos celulares e regiões cerebrais. Não é um 
interruptor, mas sim um gradiente. Quando a barreira afrouxa, quatro vias — 
que podem coexistir — ganham consequências. Primeiro, a instabilidade 
genômica local: inserções e rearranjos falhos criam quebras no genoma e 
sobrecarregam os mecanismos de reparo de DNA; em neurônios, onde energia e 
homeostase são preciosas, pequenos custos crônicos acumulam dano. Segundo, o 
ruído regulatório, com endereço: promotores e enhancers “fora de lugar” 
desalinham programas de expressão gênica que são circuitos finamente 
regulados; escorregões discretos mudam limiares de excitabilidade e de 
resposta ao estresse, por exemplo. Terceiro, o perigo reconhecido pela 
imunidade inata: transcritos (ou o DNA citosólico) de elementos móveis 
acionam “sensores de perigo”, alimentando uma neuroinflamação de baixo 
grau — um fogo lento que retroalimenta a desorganização genômica e de 
circuitos celulares. Quarto, o mosaicismo somático: ao longo da vida, eventos 
raros criam micro populações celulares distintas; o tecido torna-se um 
mosaico dinâmico, a doença heterogênea por construção. Essas vias se 
entrelaçam em ciclos complexos de feedback. Exigir uma “bala de prata” 
causal (“X causa Y”) é ser simplista e mutilar a arquitetura do fenômeno. 
A boa parcimônia organiza a complexidade; não a extirpa.

Há aqui também uma lição de método. Nos campos de milho, Barbara 
McClintock (quem descobriu os elementos transponíveis) observou padrões não 
usuais — marcas citogenéticas que sugeriam genes saltadores (elementos 
transponíveis). A comunidade científica considerou a ideia improvável 
demais. Décadas depois, a noção de transposição não apenas foi aceita, 
mas também celebrada. O improvável, investigado com rigor, muda o que 
chamamos de provável (para saber mais 
<{{ site.url }}{{ site.baseurl }}{% post_url 2025-07-18-uma-cientista-muito-a-frente-de-seu-tempo %}>).
Em ciência, anomalias recorrentes não são sujeitas ao dado; são 
convites. Tratar o “junk DNA” como lixo foi, em parte, confundir o 
inusitado com o irrelevante. Em neurodegeneração, proteger o improvável de 
um descarte apressado significa perguntar onde e quando ele de fato importa: em 
que tipo celular, em que região, em que janela temporal da doença o efeito se 
manifesta; quais predições diferenciadoras ele permite; que achado o 
derrubaria; e que biomarcadores acessíveis o capturam de modo útil ao 
paciente. É assim que a parcimônia ganha ponta: corta o excesso, preserva a 
estrutura real.

Esse mesmo cuidado com o improvável esclarece o papel da inteligência 
artificial (IA). A IA é uma ferramenta extremamente útil. Ela pode integrar 
dados dispersos, detectar padrões latentes, priorizar hipóteses e acelerar os 
ciclos de investigação. Em neurodegeneração, ela pode ajudar a ordenar a 
heterogeneidade, a revelar estruturas que a inspeção humana não alcança, no 
geral, com facilidade. Mas a IA aprende do passado humano: depende de dados 
coletados, rotulados e interpretados por nós, fundamentados em teorias e 
decisões metodológicas humanas. Por construção, ela comprime o mundo em 
representações; algo sempre fica de fora. Fora da distribuição de treino, 
diante da heterogeneidade clínica e da mudança temporal, a IA pode errar com 
certa frequência. Seu lugar, portanto, é instrumental: organizar o caos e 
gerar boas perguntas, sem decretar verdades.

Pense num relógio analógico travado às 10:15: ele acerta duas vezes ao dia, 
mas não sabe as horas — apenas repete. Um modelo treinado num recorte 
estreito do mundo faz o mesmo: reproduz as regularidades daquele recorte; 
funciona quando o contexto é familiar e erra com confiança quando o cenário 
muda. Veja um exemplo concreto: modelos generativos de imagem — como os que 
alimentam sistemas do tipo ChatGPT — tendem a desenhar relógios mostrando 
10:10/10:15. Não é porque “sabem” que horas são; é porque a maioria das 
fotos de relógios em catálogos e anúncios mostra exatamente essa hora (mãos 
simétricas, “sorriso” visual, logotipo desobstruído no topo, ponteiros 
sem se sobrepor). O modelo aprende essa moda visual a partir do conjunto de 
treino e a repete — não mede o tempo. O que “destrava” os ponteiros não 
é pedir mais imagens; é rever o mecanismo: confrontar o modelo com 
conhecimento biológico ou físico relevante, formular hipóteses explícitas e 
buscar novas evidências que as confirmem ou derrubem.

O que fazer, então, diante desse impasse? De um lado, o labirinto da 
complexidade neurodegenerativa; do outro, a navalha que, ao simplificar demais, 
nos cega ao essencial. A inteligência artificial, nossa ferramenta mais 
poderosa para navegar neste caos, corre o risco de ser apenas um relógio 
parado às 10:15, mestre em replicar o passado, mas incapaz de compreender o 
presente. O caminho não está em escolher entre a navalha e o labirinto, mas 
em encontrar um equilíbrio produtivo. É preciso um método que abrace a 
complexidade para entender, mas que saiba simplificar para agir.

Traduzir esse equilíbrio para a prática implica algumas mudanças de hábito 
e conceituais. No diagnóstico, trocar a obsessão pelo biomarcador único por 
painéis multiparamétricos que combinem imunologia, genômica, neuroimagem e 
cognição, com espaço para a heterogeneidade e o tempo — subtipos, 
trajetórias, reavaliações periódicas — e comunicação honesta de 
incerteza. No prognóstico, integrar contexto (idade, comorbidades, genética) 
à dinâmica (o mesmo marcador pode mudar de papel ao longo da doença), 
evitando decisões rígidas fundadas em substitutos frágeis. Na terapêutica, 
preferir combinações racionais — estabilização genômica, modulação 
inflamatória, ajustes metabólicos — moduladas por tipo celular, região e 
estágio, e ensaios adaptativos com enriquecimento por endofenótipo e 
endpoints multimodais. Na ética e na governança, cuidar da equidade de 
acesso, exigir transparência sobre limites e validação e priorizar desfechos 
de vida real.

Para não perder a mão, vale um lembrete operacional: hipóteses simples o 
suficiente para orientar a ação, completas o bastante para não trair o 
paciente. Dizer explicitamente o que o modelo não captura. Testar onde a 
hipótese deve falhar — em subgrupos, contextos e tempos distintos. Priorizar 
predições mecanísticas em relação às correlações inerentes. Medir o que 
importa ao paciente. Revisar pressupostos à luz de anomalias persistentes. 
Usar IA como instrumento; deixar que mecanismos guiem a decisão.

Partindo do problema real — a neurodegeneração como uma trajetória 
complexa —, vimos por que a Navalha de Ockham é necessária, mas 
insuficiente quando vira dogma. Reduzir nos permite trabalhar, mas só reduzir 
nos faz errar. O caso dos elementos móveis mostra que preservar a arquitetura 
do fenômeno abre espaço para hipóteses testáveis, alvos 
contexto-dependentes e biomarcadores úteis. A IA entra aí: acelera o caminho 
e amplia nosso alcance, mas caminha sobre o piso do conhecimento humano. Sem 
teoria e validação, todo acerto pode ser apenas “um 10:15”. Entre a 
navalha e o labirinto, a ciência clínica progride quando simplifica para agir 
e complexifica para acertar — nessa ordem.
